\documentclass[10pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{tikz}
\usetikzlibrary{positioning,matrix,decorations.pathreplacing}
\geometry{a4paper, margin=1in}

\title{
    Review of Goodfellow et al. (2020) \\
}
\author{Matthew Evans}
\date{April 30, 2025}

\begin{document}

\maketitle

\section*{Overview}
% - Understand the problem or issue that the authors' work addresses and what they aimed to achieve, and be able to articulate the problem or issue using absolutely no technical jargon.
Goodfellow et al. \cite{10.1145/3422622} address the limitations of traditional generative methods, which relied on costly approximations and often produced unconvincing outputs. They propose a two-network adversarial framework: a generator creates samples and a discriminator evaluates their authenticity. Through this competition, the generator progressively learns to produce high-quality, realistic data without complex inference procedures.


\section*{Approach}
\subsection*{Prior Work}
Prior to the authors' work, deep generative models had limited impact due to challenges in computing the maximum likelihood estimate, and their inability to take advantage of piecewise linear units (e.g., \texttt{ReLU}) which mitigate the vanishing-gradient problem in deep networks.

% - Understand and articulate how things were done prior to the innovation described in the paper.
\begin{itemize}
    \item \textbf{Deep Graphical Models} such as \textit{deep belief networks} and \textit{autoregressive decoders} specify an explicit joint probability, computed via MLE. Computing this exact likelihood is computationally expensive. GANs sidestep costly MLE through pure backpropagation.
    \item \textbf{Deep Undirected Graphical Models} such as \textit{Boltzmann machines} define the joint probability \(p(x)\) in terms of an unnormalized energy function and need Markov Chains Monte Carlo (MCMC) to approximate both gradients and sampling resulting in high computational cost. GANs eliminate MCMC entirely; sampling involves a single forward pass through \(G\).
    \item \textbf{Generative Auto-encoders} such as variational autoencoders (VAEs), like GANs, use a generator with a second network–in this case, a recognition model–however unlike GANs, VAEs reconstruct data using a pixel-wise Gaussian log-likelihood which must be averaged over all plausible outputs, resulting in blurry or overly smooth generated samples. GANs eliminate this issue by using learned adversarial loss rather than a reconstruction loss.
\end{itemize}

\subsection*{Novelty}
% - Understand and articulate what is novel about the author's approach, and what about it is particularly promising.

The authors' approach sidesteps the historical challenge of computing approximates to MLE and instead frames the problem of learning a generator as a adversarial minimax game with two competing learning models: the \textit{generator} \(G\) and the \textit{discriminator} \(D\). Under this scheme, \(G\) learns how to generate new samples which are indistinguishable from those in the training data, while \(D\) provides feedback to \(G\) by learning to discriminate between samples from the training data and samples generated by \(G\). In this way, \(D\) coaches \(G\) into producing every closer approximations to the true sample distribution.

More formally, given a random noise vector \(z \sim p_z(z)\), \(G(z; \theta_g)\) aims to approximate the true data distribution \(p_{data}(x)\). Concurrently, \(D(x; \theta_d) \in [0, 1]\) is trained to output the probability that \(x\) comes from the \(p_{data}(x)\) rather than \(G\). These models compete according to the minimax objective
\[
    \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]
\]
seeking equilibrium, at which \(G\) perfectly matches \(p_{data}\) and \(D = \frac{1}{2}\).

\subsubsection*{Theoretical Results}
The authors give proof of results under optimal conditions. These results, while idealized and theoretical, help explain the success of the model.

\vspace{0.5cm}
\noindent
\textbf{Proposition 1.} For \(G\) fixed, the optimal discriminator \(D\) is
\[
    D^*_G(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}
\]
\vspace{0.5cm}

\noindent
This result guarantees that the minimax game converges precisely when \(p_g = p_{data}\).

\vspace{0.5cm}
\noindent
\textbf{Theorem 1.} The global minimum of the virtual training criterion \(C(G)\) is achieved if and only if \(p_g = p_{data}\). At that point, \(C(G)\) achieves the value of \(-\log 4\).

\vspace{0.5cm}
\noindent
The virtual training criterion, which is given by
\[
    C(G) =  \max_D V(G, D) = \mathbb{E}_{x \sim p_{data}}[\log D^*(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D^*(G(z)))]
\]
is a function of the generator alone that–when minimized–drives \(p_g\) toward \(p_{data}\).

This result shows that, in the idealized infinite-capacity setting, the adversarial training objective has a unique global minimum achieved if and only if \(p_g\) exactly matches the true data distribution \(p_{data}\), thereby providing a guarantee that the minimax game converges to the correct solution rather than just some arbitrary saddle point.

\vspace{0.5cm}
\noindent
\textbf{Proposition 2.} If \(G\) and \(D\) have enough capacity, and at each step of Algorithm 1, the discriminator is allowed to reach its optimum given \(G\), and \(p_g\) is updated so as to improve the criterion
\[
    \mathbb{E}_{x \sim p_{data}}[\log D^*_G(x)] + \mathbb{E}_{x \sim p_g}[log(1 - D^*_G(x))]
\]
then \(p_g\) converges to \(p_{data}\).

\vspace{0.5cm}

\noindent
This result shows that by keeping the discriminator optimal at each step, the simple alternating by alternating updates between \(G\) and \(D\) will indeed drive the generator's distribution \(p_g\)to converge to the true data distribution \(p_{data}\), thereby providing a concrete convergence guarantee for the training procedure.


\section*{Considerations}
% - Understand and articulate the risks and/or weaknesses of the author's approach.
% - Understand and articulate the key benefits and/or strengths of the author's approach
\subsection*{Strengths}
\begin{itemize}
    \item \textbf{Inference free training:} Training relies solely on backpropagation; no approximate inference networks or Markov chains are needed.
    \item \textbf{Flexibility:} Any differentiable function can be used in the generator or discriminator networks allowing for a variety of model designs.
    \item \textbf{Distribution representation fidelity:} GANs are capable of modeling un-smooth and degenerate distributions that MCMC-based methods struggle with.
\end{itemize}
\subsection*{Weaknesses}
\begin{itemize}
    \item \textbf{No explicit PDF:} There is no closed form of the learned distribution \(p_g(x)\), so likelihoods must be estimated indirectly (e.g., with Parzen windows).
    \item \textbf{Training instability:} The update ratio of the competing generator and discriminator models must be properly tuned, otherwise training may collapse resulting in the generator converging to a single output for every noise input \(z\), losing generative diversity. Similarly, the discriminator must be kept near its optimum so as to provide useful learning signals (gradients) to the generator.
\end{itemize}

\section*{Measures of Success}
% - Understand and articulate the measures of success the authors used to validate their findings.

The authors evaluate their model by estimating the probability of the test set data under the learned distribution \(p_g\) by fitting a Gaussian Parzen window to the samples generated with \(G\) and reporting the log-likelihood under this distribution. The authors note that while this metric is imperfect, it is the best means of quantitative comparison available to them. Their results indicate (then) state of the art performance on the MNIST dataset and are within the margin of error for state of the art on the Toronto Face Database (TFD) dataset.
The authors also provide visualizations of generated samples from both MNIST and TFD as indication of their generative framework's potential.

\section*{Impact}
% - Understand and articulate the impact of the innovations described in the paper.
Eliminating the need for computationally costly approximate inference techniques in deep generative models, \textit{Generative Adversarial Nets} sparked a new research subfield in which many variants have been proposed such as conditional GANs, image-to-image translation, and style transfer models.
While the state-of-the-art has moved beyond GANs for tasks such as image generation, their introduction kick-started an era of learning to generate high-quality data through training a neural generator via an adversarial loss.

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}